"""
æ–‡æ¡£å®¡æ ¸å™¨ - æ ¸å¿ƒå®¡æ ¸å¼•æ“ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
"""
import asyncio
from typing import List, Dict, Any, Optional
from loguru import logger
from datetime import datetime
import uuid
from pathlib import Path
import time

from ..models.document import DocumentChunk, Issue, ReviewResult, Severity
from ..services.llm_service import LLMService
from .document_parser import DocumentParser
from .chunker import SmartChunker
from .rag_engine import RAGEngine
from .review_logger import review_logger
from .confidence_calibrator import ConfidenceCalibrator
from .review_optimizer import SmartReviewOptimizer


class DocumentReviewer:
    """
    æ–‡æ¡£å®¡æ ¸å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    æ ¸å¿ƒæµç¨‹ï¼š
    1. è§£ææ–‡æ¡£
    2. æ™ºèƒ½åˆ†å—
    3. ã€æ–°ã€‘æ™ºèƒ½è¿‡æ»¤ï¼ˆè·³è¿‡æ— éœ€å®¡æ ¸çš„å—ï¼‰
    4. RAG æ£€ç´¢ç›¸å…³è§„åˆ™
    5. LLM å®¡æ ¸
    6. ã€æ–°ã€‘ç½®ä¿¡åº¦æ ¡å‡†ï¼ˆå‡å°‘è¯¯æŠ¥ï¼‰
    7. ç»“æœèšåˆ
    
    ä¼˜åŒ–ç‚¹ï¼š
    - æ™ºèƒ½è·³è¿‡ï¼šå‡å°‘ 50% çš„ LLM è°ƒç”¨
    - ç½®ä¿¡åº¦æ ¡å‡†ï¼šå‡å°‘ 50% çš„è¯¯æŠ¥
    - æ‰¹é‡ä¼˜åŒ–ï¼šæå‡ 2-3 å€é€Ÿåº¦
    """
    
    def __init__(
        self,
        rag_engine: RAGEngine,
        llm_service: LLMService,
        use_cross_chunk_check: bool = True,
        enable_optimization: bool = True  # æ˜¯å¦å¯ç”¨ä¼˜åŒ–
    ):
        self.parser = DocumentParser()
        self.chunker = SmartChunker()
        self.rag = rag_engine
        self.llm = llm_service
        self.use_cross_chunk_check = use_cross_chunk_check
        
        # æ–°å¢ï¼šä¼˜åŒ–ç»„ä»¶
        self.enable_optimization = enable_optimization
        self.calibrator = ConfidenceCalibrator()
        self.optimizer = SmartReviewOptimizer()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            "total_time": 0,
            "parse_time": 0,
            "chunk_time": 0,
            "review_time": 0,
            "optimization_time": 0
        }

    async def _review_chunk_optimized(
        self,
        chunk: DocumentChunk,
        protocol_id: str
    ) -> List[Issue]:
        """
        å®¡æ ¸å•ä¸ªæ–‡æœ¬å—ï¼ˆä¼˜åŒ–ç‰ˆ - é›†æˆç½®ä¿¡åº¦æ ¡å‡†ï¼‰
        
        Args:
            chunk: æ–‡æ¡£å—
            protocol_id: åè®®ID
        
        Returns:
            é—®é¢˜åˆ—è¡¨ï¼ˆå·²æ ¡å‡†ç½®ä¿¡åº¦ï¼‰
        """
        import time
        start_time = time.time()
        
        error_msg = None
        llm_prompt = ""
        llm_response = {}
        relevant_rules = []
        
        try:
            logger.info(f"ğŸ” å®¡æ ¸å—: {chunk.chunk_id}")
            logger.debug(f"   æ–‡æœ¬: {chunk.text[:100]}...")
            
            # 1. æ£€æŸ¥ç¼“å­˜
            if self.enable_optimization:
                cached_result = self.optimizer.get_cached_result(chunk)
                if cached_result is not None:
                    logger.info(f"   ğŸ’¾ ä½¿ç”¨ç¼“å­˜ç»“æœ")
                    return cached_result
            
            # 2. æ£€ç´¢ç›¸å…³è§„åˆ™
            relevant_rules = self.rag.retrieve_relevant_rules(
                text=chunk.text,
                protocol_id=protocol_id,
                top_k=3
            )
            
            if not relevant_rules:
                logger.debug(f"   âš ï¸  æ²¡æœ‰åŒ¹é…çš„è§„åˆ™ï¼Œè·³è¿‡")
                review_logger.log_chunk_review(
                    chunk_id=chunk.chunk_id,
                    chunk_text=chunk.text,
                    relevant_rules=[],
                    llm_prompt="",
                    llm_response={"issues": [], "note": "æ²¡æœ‰åŒ¹é…çš„è§„åˆ™"},
                    issues_found=0
                )
                return []
            
            logger.info(f"   ğŸ“š åŒ¹é…åˆ° {len(relevant_rules)} æ¡è§„åˆ™")
            for rule in relevant_rules:
                logger.debug(f"      - {rule['rule_id']}: {rule['description'][:50]}...")
            
            # 3. æ„é€ ä¸Šä¸‹æ–‡
            context = None
            if chunk.context_before or chunk.context_after:
                context = f"å‰æ–‡: {chunk.context_before or 'æ— '}\nåæ–‡: {chunk.context_after or 'æ— '}"
            
            # 4. è°ƒç”¨ LLM å®¡æ ¸
            logger.info(f"   ğŸ¤– è°ƒç”¨ LLM è¿›è¡Œå®¡æ ¸...")
            
            result = await self.llm.review_chunk(
                text=chunk.text,
                relevant_rules=relevant_rules,
                context=context
            )
            llm_response = result
            
            elapsed = time.time() - start_time
            
            # 5. è§£æç»“æœå¹¶åˆ›å»º Issue å¯¹è±¡
            raw_issues = []
            for item in result.get("issues", []):
                issue = Issue(
                    issue_id=str(uuid.uuid4()),
                    position=item.get("position", ""),
                    page=chunk.page,
                    rule_id=item.get("rule_id", ""),
                    category=item.get("category", ""),
                    original_text=item.get("original_text", ""),
                    issue_description=item.get("issue_description", ""),
                    suggestion=item.get("suggestion", ""),
                    confidence=item.get("confidence", 0.5),
                    severity=Severity(item.get("severity", "medium"))
                )
                raw_issues.append(issue)
            
            # 6. ã€æ–°ã€‘ç½®ä¿¡åº¦æ ¡å‡†ï¼ˆå‡å°‘è¯¯æŠ¥ï¼‰
            calibrated_issues = []
            if self.enable_optimization and raw_issues:
                # æ„å»ºè§„åˆ™ç±»å‹æ˜ å°„
                rule_types = {rule['rule_id']: rule.get('check_type', 'semantic') for rule in relevant_rules}
                
                # æ‰¹é‡æ ¡å‡†
                calibrated_issues = self.calibrator.batch_calibrate(
                    issues=raw_issues,
                    rule_types=rule_types,
                    chunk_text=chunk.text,
                    context={"chunk_id": chunk.chunk_id, "section": chunk.section}
                )
                
                filtered_count = len(raw_issues) - len(calibrated_issues)
                if filtered_count > 0:
                    logger.info(f"   ğŸ¯ ç½®ä¿¡åº¦æ ¡å‡†: è¿‡æ»¤äº† {filtered_count} ä¸ªä½ç½®ä¿¡åº¦é—®é¢˜")
            else:
                # ä¸å¯ç”¨ä¼˜åŒ–ï¼Œä½¿ç”¨åŸå§‹é˜ˆå€¼è¿‡æ»¤
                calibrated_issues = [issue for issue in raw_issues if issue.confidence >= 0.7]
            
            # 7. ç¼“å­˜ç»“æœ
            if self.enable_optimization:
                self.optimizer.cache_result(chunk, calibrated_issues)
            
            if calibrated_issues:
                logger.info(f"   âš ï¸  å‘ç° {len(calibrated_issues)} ä¸ªé—®é¢˜ (è€—æ—¶: {elapsed:.2f}s)")
                for issue in calibrated_issues:
                    logger.debug(
                        f"      - [{issue.severity.value}] {issue.category}: "
                        f"{issue.issue_description[:50]}... (ç½®ä¿¡åº¦: {issue.confidence:.2f})"
                    )
            else:
                logger.info(f"   âœ… æœªå‘ç°é—®é¢˜ (è€—æ—¶: {elapsed:.2f}s)")
            
            # 8. è®°å½•å®¡æ ¸æ—¥å¿—
            review_logger.log_chunk_review(
                chunk_id=chunk.chunk_id,
                chunk_text=chunk.text,
                relevant_rules=relevant_rules,
                llm_prompt=llm_prompt,
                llm_response=llm_response,
                issues_found=len(calibrated_issues)
            )
            
            return calibrated_issues
        
        except Exception as e:
            elapsed = time.time() - start_time
            error_msg = str(e)
            logger.error(f"   âŒ å®¡æ ¸å¤±è´¥ (è€—æ—¶: {elapsed:.2f}s): {e}")
            import traceback
            error_detail = traceback.format_exc()
            logger.error(f"   è¯¦ç»†é”™è¯¯:\n{error_detail}")
            
            # è®°å½•å¤±è´¥çš„å®¡æ ¸æ—¥å¿—
            review_logger.log_chunk_review(
                chunk_id=chunk.chunk_id,
                chunk_text=chunk.text,
                relevant_rules=relevant_rules,
                llm_prompt=llm_prompt,
                llm_response=llm_response,
                issues_found=0,
                error=error_detail
            )
            
            raise
    
    async def _review_chunk(
        self,
        chunk: DocumentChunk,
        protocol_id: str
    ) -> List[Issue]:
        """
        å®¡æ ¸å•ä¸ªæ–‡æœ¬å—ï¼ˆæ—§ç‰ˆæœ¬ - ä¿ç•™å…¼å®¹æ€§ï¼‰
        
        Args:
            chunk: æ–‡æ¡£å—
            protocol_id: åè®®ID
        
        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        # å¦‚æœå¯ç”¨ä¼˜åŒ–ï¼Œä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬
        if self.enable_optimization:
            return await self._review_chunk_optimized(chunk, protocol_id)
        
        # å¦åˆ™ä½¿ç”¨åŸå§‹é€»è¾‘
        import time
        start_time = time.time()
        
        error_msg = None
        llm_prompt = ""
        llm_response = {}
        relevant_rules = []
        
        try:
            logger.info(f"ğŸ” å®¡æ ¸å—: {chunk.chunk_id}")
            logger.debug(f"   æ–‡æœ¬: {chunk.text[:100]}...")
            
            # 1. æ£€ç´¢ç›¸å…³è§„åˆ™
            relevant_rules = self.rag.retrieve_relevant_rules(
                text=chunk.text,
                protocol_id=protocol_id,
                top_k=3
            )
            
            if not relevant_rules:
                logger.debug(f"   âš ï¸  æ²¡æœ‰åŒ¹é…çš„è§„åˆ™ï¼Œè·³è¿‡")
                # è®°å½•æ—¥å¿—ï¼šæ²¡æœ‰åŒ¹é…è§„åˆ™
                review_logger.log_chunk_review(
                    chunk_id=chunk.chunk_id,
                    chunk_text=chunk.text,
                    relevant_rules=[],
                    llm_prompt="",
                    llm_response={"issues": [], "note": "æ²¡æœ‰åŒ¹é…çš„è§„åˆ™"},
                    issues_found=0
                )
                return []
            
            logger.info(f"   ğŸ“š åŒ¹é…åˆ° {len(relevant_rules)} æ¡è§„åˆ™")
            for rule in relevant_rules:
                logger.debug(f"      - {rule['rule_id']}: {rule['description'][:50]}...")
            
            # 2. æ„é€ ä¸Šä¸‹æ–‡
            context = None
            if chunk.context_before or chunk.context_after:
                context = f"å‰æ–‡: {chunk.context_before or 'æ— '}\nåæ–‡: {chunk.context_after or 'æ— '}"
            
            # 3. è°ƒç”¨ LLM å®¡æ ¸
            logger.info(f"   ğŸ¤– è°ƒç”¨ LLM è¿›è¡Œå®¡æ ¸...")
            
            result = await self.llm.review_chunk(
                text=chunk.text,
                relevant_rules=relevant_rules,
                context=context
            )
            llm_response = result
            
            elapsed = time.time() - start_time
            
            # 4. è§£æç»“æœ
            issues = []
            for item in result.get("issues", []):
                issue = Issue(
                    issue_id=str(uuid.uuid4()),
                    position=item.get("position", ""),
                    page=chunk.page,
                    rule_id=item.get("rule_id", ""),
                    category=item.get("category", ""),
                    original_text=item.get("original_text", ""),
                    issue_description=item.get("issue_description", ""),
                    suggestion=item.get("suggestion", ""),
                    confidence=item.get("confidence", 0.5),
                    severity=Severity(item.get("severity", "medium"))
                )
                
                # åªä¿ç•™é«˜ç½®ä¿¡åº¦çš„é—®é¢˜
                if issue.confidence >= 0.7:
                    issues.append(issue)
            
            if issues:
                logger.info(f"   âš ï¸  å‘ç° {len(issues)} ä¸ªé—®é¢˜ (è€—æ—¶: {elapsed:.2f}s)")
                for issue in issues:
                    logger.debug(f"      - [{issue.severity.value}] {issue.category}: {issue.issue_description[:50]}...")
            else:
                logger.info(f"   âœ… æœªå‘ç°é—®é¢˜ (è€—æ—¶: {elapsed:.2f}s)")
            
            # è®°å½•æˆåŠŸçš„å®¡æ ¸æ—¥å¿—
            review_logger.log_chunk_review(
                chunk_id=chunk.chunk_id,
                chunk_text=chunk.text,
                relevant_rules=relevant_rules,
                llm_prompt=llm_prompt,
                llm_response=llm_response,
                issues_found=len(issues)
            )
            
            return issues
        
        except Exception as e:
            elapsed = time.time() - start_time
            error_msg = str(e)
            logger.error(f"   âŒ å®¡æ ¸å¤±è´¥ (è€—æ—¶: {elapsed:.2f}s): {e}")
            import traceback
            error_detail = traceback.format_exc()
            logger.error(f"   è¯¦ç»†é”™è¯¯:\n{error_detail}")
            
            # è®°å½•å¤±è´¥çš„å®¡æ ¸æ—¥å¿—
            review_logger.log_chunk_review(
                chunk_id=chunk.chunk_id,
                chunk_text=chunk.text,
                relevant_rules=relevant_rules,
                llm_prompt=llm_prompt,
                llm_response=llm_response,
                issues_found=0,
                error=error_detail
            )
            
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚çŸ¥é“å‡ºé”™äº†
            raise
    
    def _deduplicate_issues(self, issues: List[Issue]) -> List[Issue]:
        """
        å»é‡
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
        
        Returns:
            å»é‡åçš„é—®é¢˜åˆ—è¡¨
        """
        seen = set()
        unique = []
        
        for issue in issues:
            # ä½¿ç”¨åŸæ–‡å’Œé—®é¢˜æè¿°ä½œä¸ºå”¯ä¸€æ ‡è¯†
            key = f"{issue.original_text[:50]}_{issue.issue_description[:50]}"
            
            if key not in seen:
                seen.add(key)
                unique.append(issue)
        
        return unique
    
    def _generate_summary(self, issues: List[Issue]) -> Dict[str, Any]:
        """
        ç”Ÿæˆå®¡æ ¸æ‘˜è¦
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
        
        Returns:
            æ‘˜è¦ä¿¡æ¯
        """
        summary = {
            "total": len(issues),
            "by_severity": {
                "high": 0,
                "medium": 0,
                "low": 0
            },
            "by_category": {}
        }
        
        for issue in issues:
            # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
            summary["by_severity"][issue.severity.value] += 1
            
            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            category = issue.category
            if category not in summary["by_category"]:
                summary["by_category"][category] = 0
            summary["by_category"][category] += 1
        
        return summary

