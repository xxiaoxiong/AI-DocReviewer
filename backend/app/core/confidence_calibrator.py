"""
ç½®ä¿¡åº¦æ ¡å‡†å™¨ - å‡å°‘è¯¯æŠ¥
"""
from typing import Dict, Any
from loguru import logger

from ..models.document import Issue, Severity


class ConfidenceCalibrator:
    """
    ç½®ä¿¡åº¦æ ¡å‡†å™¨
    
    åŠŸèƒ½ï¼š
    1. æ ¹æ®è§„åˆ™ç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
    2. æ ¹æ®æ–‡æœ¬ç‰¹å¾è°ƒæ•´ç½®ä¿¡åº¦ 
    3. æ ¹æ®å†å²å‡†ç¡®ç‡è°ƒæ•´ç½®ä¿¡åº¦
    4. åŠ¨æ€é˜ˆå€¼è¿‡æ»¤
    
    ç›®æ ‡ï¼šå‡å°‘è¯¯æŠ¥ 50%
    """
    
    def __init__(self):
        # è§„åˆ™ç±»å‹æƒé‡ï¼ˆåŸºäºç»éªŒï¼‰
        self.rule_type_weights = {
            "format": 1.2,      # æ ¼å¼ç±»è§„åˆ™æ›´å¯é ï¼ˆå¦‚ï¼šæ ‡ç‚¹ã€ç©ºæ ¼ï¼‰
            "semantic": 0.85,   # è¯­ä¹‰ç±»è§„åˆ™éœ€è¦æ›´è°¨æ…ï¼ˆå¦‚ï¼šé€»è¾‘è¿è´¯æ€§ï¼‰
            "structure": 1.0,   # ç»“æ„ç±»è§„åˆ™æ ‡å‡†æƒé‡ï¼ˆå¦‚ï¼šç« èŠ‚é¡ºåºï¼‰
            "content": 0.9      # å†…å®¹ç±»è§„åˆ™ç¨å¾®è°¨æ…ï¼ˆå¦‚ï¼šç”¨è¯è§„èŒƒï¼‰
        }
        
        # ä¸¥é‡åº¦æƒé‡ï¼ˆé«˜ä¸¥é‡åº¦è¦æ±‚æ›´é«˜ç½®ä¿¡åº¦ï¼‰
        self.severity_weights = {
            "high": 1.1,    # é«˜ä¸¥é‡åº¦é—®é¢˜è¦æ±‚æ›´ç¡®å®š
            "medium": 1.0,  # ä¸­ç­‰ä¸¥é‡åº¦æ ‡å‡†
            "low": 0.9      # ä½ä¸¥é‡åº¦å¯ä»¥å®½æ¾ä¸€äº›
        }
        
        # å†å²å‡†ç¡®ç‡ï¼ˆå¯ä»¥ä»æ—¥å¿—ä¸­å­¦ä¹ ï¼‰
        self.rule_accuracy_history = {}
    
    def calibrate_issue(
        self,
        issue: Issue,
        rule_type: str,
        chunk_text: str,
        context: Dict[str, Any] = None
    ) -> Issue:
        """
        æ ¡å‡†å•ä¸ªé—®é¢˜çš„ç½®ä¿¡åº¦
        
        Args:
            issue: åŸå§‹é—®é¢˜
            rule_type: è§„åˆ™ç±»å‹
            chunk_text: åŸå§‹æ–‡æœ¬å—
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            æ ¡å‡†åçš„é—®é¢˜
        """
        original_confidence = issue.confidence
        
        # 1. è§„åˆ™ç±»å‹æƒé‡
        type_weight = self.rule_type_weights.get(rule_type, 1.0)
        
        # 2. ä¸¥é‡åº¦æƒé‡
        severity_weight = self.severity_weights.get(issue.severity.value, 1.0)
        
        # 3. æ–‡æœ¬é•¿åº¦æƒé‡ï¼ˆå¤ªçŸ­çš„åŸæ–‡å¯èƒ½ä¸å¯é ï¼‰
        length_weight = self._calculate_length_weight(issue.original_text)
        
        # 4. ä¸Šä¸‹æ–‡ä¸€è‡´æ€§æƒé‡
        context_weight = self._calculate_context_weight(issue, chunk_text, context)
        
        # 5. å†å²å‡†ç¡®ç‡æƒé‡
        history_weight = self._get_history_weight(issue.rule_id)
        
        # ç»¼åˆæ ¡å‡†
        calibrated_confidence = (
            original_confidence 
            * type_weight 
            * severity_weight 
            * length_weight 
            * context_weight 
            * history_weight
        )
        
        # é™åˆ¶åœ¨ [0, 1] èŒƒå›´
        calibrated_confidence = max(0.0, min(1.0, calibrated_confidence))
        
        # è®°å½•æ ¡å‡†ä¿¡æ¯
        if abs(calibrated_confidence - original_confidence) > 0.1:
            logger.debug(
                f"ç½®ä¿¡åº¦æ ¡å‡†: {issue.rule_id} "
                f"{original_confidence:.2f} -> {calibrated_confidence:.2f} "
                f"(ç±»å‹:{type_weight:.2f}, ä¸¥é‡åº¦:{severity_weight:.2f}, "
                f"é•¿åº¦:{length_weight:.2f}, ä¸Šä¸‹æ–‡:{context_weight:.2f}, "
                f"å†å²:{history_weight:.2f})"
            )
        
        # æ›´æ–°ç½®ä¿¡åº¦
        issue.confidence = calibrated_confidence
        
        return issue
    
    def _calculate_length_weight(self, original_text: str) -> float:
        """
        è®¡ç®—æ–‡æœ¬é•¿åº¦æƒé‡
        
        åŸåˆ™ï¼š
        - å¤ªçŸ­ï¼ˆ<10å­—ç¬¦ï¼‰ï¼šç½®ä¿¡åº¦é™ä½ï¼ˆå¯èƒ½æ˜¯è¯¯æŠ¥ï¼‰
        - é€‚ä¸­ï¼ˆ10-50å­—ç¬¦ï¼‰ï¼šæ ‡å‡†æƒé‡
        - å¤ªé•¿ï¼ˆ>100å­—ç¬¦ï¼‰ï¼šç½®ä¿¡åº¦ç•¥å¾®é™ä½ï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªé—®é¢˜ï¼‰
        """
        length = len(original_text.strip())
        
        if length < 10:
            # å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯è¯¯æŠ¥
            return 0.6
        elif length < 20:
            # è¾ƒçŸ­ï¼Œç¨å¾®é™ä½
            return 0.8
        elif length <= 50:
            # é€‚ä¸­ï¼Œæ ‡å‡†æƒé‡
            return 1.0
        elif length <= 100:
            # è¾ƒé•¿ï¼Œç•¥å¾®é™ä½
            return 0.95
        else:
            # å¤ªé•¿ï¼Œå¯èƒ½ä¸å¤Ÿç²¾ç¡®
            return 0.85
    
    def _calculate_context_weight(
        self,
        issue: Issue,
        chunk_text: str,
        context: Dict[str, Any]
    ) -> float:
        """
        è®¡ç®—ä¸Šä¸‹æ–‡ä¸€è‡´æ€§æƒé‡
        
        æ£€æŸ¥ï¼š
        1. åŸæ–‡æ˜¯å¦çœŸçš„åœ¨æ–‡æœ¬å—ä¸­
        2. é—®é¢˜æè¿°æ˜¯å¦ä¸åŸæ–‡åŒ¹é…
        3. å»ºè®®æ˜¯å¦åˆç†
        """
        weight = 1.0
        
        # æ£€æŸ¥1ï¼šåŸæ–‡æ˜¯å¦åœ¨æ–‡æœ¬å—ä¸­
        if issue.original_text not in chunk_text:
            logger.warning(f"åŸæ–‡ä¸åœ¨æ–‡æœ¬å—ä¸­: {issue.original_text[:30]}...")
            weight *= 0.5  # å¤§å¹…é™ä½ç½®ä¿¡åº¦
        
        # æ£€æŸ¥2ï¼šåŸæ–‡æ˜¯å¦åªæœ‰æ ‡ç‚¹ç¬¦å·ï¼ˆå¯èƒ½æ˜¯è¯¯æŠ¥ï¼‰
        if all(c in '()ï¼ˆï¼‰[]ã€ã€‘{}ã€Œã€ã€ã€<>ã€Šã€‹ã€ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿ\n\t ' for c in issue.original_text):
            logger.debug(f"åŸæ–‡åªæœ‰æ ‡ç‚¹ç¬¦å·: {issue.original_text}")
            weight *= 0.3  # å¤§å¹…é™ä½
        
        # æ£€æŸ¥3ï¼šåŸæ–‡æ˜¯å¦åªæœ‰æ•°å­—ï¼ˆå¯èƒ½æ˜¯è¯¯æŠ¥ï¼‰
        if issue.original_text.strip().replace(' ', '').isdigit():
            logger.debug(f"åŸæ–‡åªæœ‰æ•°å­—: {issue.original_text}")
            weight *= 0.4
        
        # æ£€æŸ¥4ï¼šé—®é¢˜æè¿°æ˜¯å¦å¤ªçŸ­ï¼ˆå¯èƒ½ä¸å¤Ÿå…·ä½“ï¼‰
        if len(issue.issue_description) < 10:
            logger.debug(f"é—®é¢˜æè¿°å¤ªçŸ­: {issue.issue_description}")
            weight *= 0.8
        
        # æ£€æŸ¥5ï¼šå»ºè®®æ˜¯å¦å¤ªçŸ­ï¼ˆå¯èƒ½ä¸å¤Ÿå…·ä½“ï¼‰
        if len(issue.suggestion) < 10:
            logger.debug(f"å»ºè®®å¤ªçŸ­: {issue.suggestion}")
            weight *= 0.9
        
        return weight
    
    def _get_history_weight(self, rule_id: str) -> float:
        """
        è·å–å†å²å‡†ç¡®ç‡æƒé‡
        
        å¦‚æœæŸæ¡è§„åˆ™å†å²ä¸Šè¯¯æŠ¥ç‡é«˜ï¼Œé™ä½å…¶ç½®ä¿¡åº¦
        """
        if rule_id not in self.rule_accuracy_history:
            return 1.0  # æ²¡æœ‰å†å²æ•°æ®ï¼Œä½¿ç”¨æ ‡å‡†æƒé‡
        
        accuracy = self.rule_accuracy_history[rule_id]
        
        # å‡†ç¡®ç‡è¶Šä½ï¼Œæƒé‡è¶Šä½
        if accuracy < 0.5:
            return 0.7
        elif accuracy < 0.7:
            return 0.85
        else:
            return 1.0
    
    def should_filter_issue(
        self,
        issue: Issue,
        min_confidence: float = 0.7
    ) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿‡æ»¤æ‰è¿™ä¸ªé—®é¢˜
        
        Args:
            issue: é—®é¢˜
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
        
        Returns:
            True è¡¨ç¤ºåº”è¯¥è¿‡æ»¤ï¼ˆä¸æŠ¥å‘Šï¼‰
        """
        # åŸºç¡€é˜ˆå€¼è¿‡æ»¤
        if issue.confidence < min_confidence:
            return True
        
        # é«˜ä¸¥é‡åº¦é—®é¢˜ï¼šæ›´ä¸¥æ ¼çš„é˜ˆå€¼
        if issue.severity == Severity.HIGH and issue.confidence < 0.85:
            logger.debug(f"é«˜ä¸¥é‡åº¦é—®é¢˜ç½®ä¿¡åº¦ä¸è¶³: {issue.confidence:.2f} < 0.85")
            return True
        
        # ä½ä¸¥é‡åº¦é—®é¢˜ï¼šå¯ä»¥å®½æ¾ä¸€äº›
        if issue.severity == Severity.LOW and issue.confidence >= 0.65:
            return False
        
        return False
    
    def batch_calibrate(
        self,
        issues: list[Issue],
        rule_types: Dict[str, str],
        chunk_text: str,
        context: Dict[str, Any] = None
    ) -> list[Issue]:
        """
        æ‰¹é‡æ ¡å‡†é—®é¢˜åˆ—è¡¨
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
            rule_types: è§„åˆ™IDåˆ°ç±»å‹çš„æ˜ å°„
            chunk_text: åŸå§‹æ–‡æœ¬å—
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            æ ¡å‡†åçš„é—®é¢˜åˆ—è¡¨ï¼ˆå·²è¿‡æ»¤ä½ç½®ä¿¡åº¦ï¼‰
        """
        calibrated_issues = []
        filtered_count = 0
        
        for issue in issues:
            rule_type = rule_types.get(issue.rule_id, "semantic")
            
            # æ ¡å‡†
            calibrated_issue = self.calibrate_issue(
                issue, rule_type, chunk_text, context
            )
            
            # è¿‡æ»¤
            if not self.should_filter_issue(calibrated_issue):
                calibrated_issues.append(calibrated_issue)
            else:
                filtered_count += 1
                logger.debug(
                    f"è¿‡æ»¤ä½ç½®ä¿¡åº¦é—®é¢˜: {issue.rule_id} "
                    f"({calibrated_issue.confidence:.2f}) - {issue.issue_description[:50]}..."
                )
        
        if filtered_count > 0:
            logger.info(f"ğŸ“Š ç½®ä¿¡åº¦æ ¡å‡†: è¿‡æ»¤äº† {filtered_count}/{len(issues)} ä¸ªä½ç½®ä¿¡åº¦é—®é¢˜")
        
        return calibrated_issues
    
    def update_history(self, rule_id: str, is_correct: bool):
        """
        æ›´æ–°è§„åˆ™çš„å†å²å‡†ç¡®ç‡
        
        Args:
            rule_id: è§„åˆ™ID
            is_correct: è¿™æ¬¡æ£€æµ‹æ˜¯å¦æ­£ç¡®
        """
        if rule_id not in self.rule_accuracy_history:
            self.rule_accuracy_history[rule_id] = {
                "correct": 0,
                "total": 0,
                "accuracy": 1.0
            }
        
        history = self.rule_accuracy_history[rule_id]
        history["total"] += 1
        if is_correct:
            history["correct"] += 1
        
        # æ›´æ–°å‡†ç¡®ç‡ï¼ˆä½¿ç”¨æ»‘åŠ¨å¹³å‡ï¼Œé¿å…æ—©æœŸæ•°æ®å½±å“è¿‡å¤§ï¼‰
        history["accuracy"] = history["correct"] / history["total"]
        
        logger.debug(
            f"æ›´æ–°è§„åˆ™å†å²: {rule_id} "
            f"å‡†ç¡®ç‡={history['accuracy']:.2f} ({history['correct']}/{history['total']})"
        )

