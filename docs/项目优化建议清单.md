# DocReviewer é¡¹ç›®ä¼˜åŒ–å»ºè®®æ¸…å•

> ç”Ÿæˆæ—¶é—´ï¼š2026å¹´2æœˆ15æ—¥

---

## ğŸš¨ é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼ˆP0 - ç«‹å³ä¿®å¤ï¼‰

### 1. API Key ç¡¬ç¼–ç é—®é¢˜ âš ï¸ å®‰å…¨é£é™©

**ä½ç½®**ï¼š`backend/run.py:60`

**é—®é¢˜**ï¼š
```python
os.environ['DEEPSEEK_API_KEY'] = 'sk-bc4ceb3384f244e38f596fd23631af63'
```

**é£é™©**ï¼š
- API Key æ³„éœ²åˆ°ä»£ç ä»“åº“
- å¯èƒ½è¢«æ»¥ç”¨ï¼Œäº§ç”Ÿè´¹ç”¨
- è¿åå®‰å…¨æœ€ä½³å®è·µ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# åˆ é™¤ç¡¬ç¼–ç ï¼Œå¼ºåˆ¶è¦æ±‚é…ç½®
if not os.environ.get('DEEPSEEK_API_KEY'):
    print("âŒ é”™è¯¯: DEEPSEEK_API_KEY æœªé…ç½®")
    print("è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶ï¼Œæ·»åŠ ï¼š")
    print("DEEPSEEK_API_KEY=your_api_key_here")
    sys.exit(1)
```

**å®æ–½æ­¥éª¤**ï¼š
1. åˆ é™¤ `run.py` ç¬¬ 60 è¡Œçš„ç¡¬ç¼–ç 
2. æ·»åŠ å¯åŠ¨æ£€æŸ¥é€»è¾‘
3. æ›´æ–° README è¯´æ˜é…ç½®æ–¹æ³•
4. æ·»åŠ  `.env.example` æ¨¡æ¿æ–‡ä»¶

---

### 2. é”™è¯¯å¤„ç†ä¸å®Œå–„

**é—®é¢˜**ï¼š
- LLM è°ƒç”¨å¤±è´¥æ—¶ï¼Œå‰ç«¯æ˜¾ç¤ºä¸å‹å¥½
- ç½‘ç»œè¶…æ—¶æ²¡æœ‰æ˜ç¡®æç¤º
- æ–‡ä»¶æ ¼å¼é”™è¯¯å¤„ç†ä¸å¤Ÿç»†è‡´

**è§£å†³æ–¹æ¡ˆ**ï¼š

**åç«¯ - å®šä¹‰é”™è¯¯ç±»å‹**ï¼š
```python
# app/services/llm_service.py
class LLMError(Exception):
    """LLM æœåŠ¡åŸºç¡€é”™è¯¯"""
    pass

class APIKeyError(LLMError):
    """API Key é…ç½®é”™è¯¯"""
    def __init__(self):
        super().__init__("API Key æœªé…ç½®æˆ–æ— æ•ˆï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

class NetworkError(LLMError):
    """ç½‘ç»œè¿æ¥é”™è¯¯"""
    def __init__(self, detail):
        super().__init__(f"ç½‘ç»œè¿æ¥å¤±è´¥: {detail}")

class RateLimitError(LLMError):
    """API è°ƒç”¨é¢‘ç‡é™åˆ¶"""
    def __init__(self):
        super().__init__("API è°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•")

class ModelError(LLMError):
    """æ¨¡å‹è¿”å›é”™è¯¯"""
    def __init__(self, detail):
        super().__init__(f"æ¨¡å‹è¿”å›é”™è¯¯: {detail}")
```

**åç«¯ - ç»Ÿä¸€é”™è¯¯å¤„ç†**ï¼š
```python
# app/api/review.py
@router.post("/document/stream")
async def review_document_stream(...):
    try:
        # å®¡æ ¸é€»è¾‘
        ...
    except APIKeyError as e:
        raise HTTPException(status_code=401, detail=str(e))
    except NetworkError as e:
        raise HTTPException(status_code=503, detail=str(e))
    except RateLimitError as e:
        raise HTTPException(status_code=429, detail=str(e))
    except Exception as e:
        logger.error(f"å®¡æ ¸å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å®¡æ ¸å¤±è´¥: {str(e)}")
```

**å‰ç«¯ - å‹å¥½é”™è¯¯æç¤º**ï¼š
```javascript
// frontend/index.html
function showError(message, type = 'error') {
    const errorDiv = document.getElementById('errorMessage');
    
    // æ ¹æ®é”™è¯¯ç±»å‹æ˜¾ç¤ºä¸åŒçš„å›¾æ ‡å’Œå»ºè®®
    let icon = 'âŒ';
    let suggestions = '';
    
    if (message.includes('API Key')) {
        icon = 'ğŸ”‘';
        suggestions = `
            <div style="margin-top: 10px; padding: 10px; background: #fff3cd; border-radius: 6px;">
                <strong>è§£å†³æ–¹æ³•ï¼š</strong><br>
                1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶<br>
                2. æ·»åŠ ï¼šDEEPSEEK_API_KEY=your_key<br>
                3. é‡å¯åç«¯æœåŠ¡
            </div>
        `;
    } else if (message.includes('ç½‘ç»œ')) {
        icon = 'ğŸŒ';
        suggestions = `
            <div style="margin-top: 10px;">
                <strong>è¯·æ£€æŸ¥ï¼š</strong><br>
                â€¢ åç«¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ<br>
                â€¢ ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸<br>
                â€¢ é˜²ç«å¢™æ˜¯å¦é˜»æ­¢è¿æ¥
            </div>
        `;
    }
    
    errorDiv.innerHTML = `${icon} ${message}${suggestions}`;
    errorDiv.classList.add('show');
}
```

---

### 3. æ—¥å¿—æŒä¹…åŒ–ç¼ºå¤±

**é—®é¢˜**ï¼š
- å®¡æ ¸æ—¥å¿—åªåœ¨å†…å­˜ä¸­
- æ— æ³•æŸ¥è¯¢å†å²è®°å½•
- ç¼ºå°‘å®¡æ ¸ç»Ÿè®¡

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ•°æ®åº“è®¾è®¡**ï¼ˆä½¿ç”¨ SQLiteï¼‰ï¼š
```python
# app/models/database.py
from sqlalchemy import create_engine, Column, Integer, String, Text, DateTime, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from datetime import datetime

Base = declarative_base()

class ReviewSession(Base):
    """å®¡æ ¸ä¼šè¯"""
    __tablename__ = 'review_sessions'
    
    id = Column(Integer, primary_key=True)
    session_id = Column(String(50), unique=True, index=True)
    filename = Column(String(255))
    protocol_id = Column(String(50))
    total_chunks = Column(Integer)
    reviewed_chunks = Column(Integer)
    total_issues = Column(Integer)
    optimization_rate = Column(Float)
    created_at = Column(DateTime, default=datetime.now)
    completed_at = Column(DateTime)
    status = Column(String(20))  # pending, completed, failed

class ReviewIssue(Base):
    """å®¡æ ¸é—®é¢˜"""
    __tablename__ = 'review_issues'
    
    id = Column(Integer, primary_key=True)
    session_id = Column(String(50), index=True)
    issue_id = Column(String(50))
    position = Column(String(100))
    rule_id = Column(String(50))
    category = Column(String(100))
    original_text = Column(Text)
    issue_description = Column(Text)
    suggestion = Column(Text)
    confidence = Column(Float)
    severity = Column(String(20))
    created_at = Column(DateTime, default=datetime.now)

# åˆå§‹åŒ–æ•°æ®åº“
engine = create_engine('sqlite:///data/docreviewer.db')
Base.metadata.create_all(engine)
SessionLocal = sessionmaker(bind=engine)
```

**æ—¥å¿—ä¿å­˜æ¥å£**ï¼š
```python
# app/api/review.py
from ..models.database import SessionLocal, ReviewSession, ReviewIssue

@router.post("/document/stream")
async def review_document_stream(...):
    # åˆ›å»ºä¼šè¯è®°å½•
    db = SessionLocal()
    session = ReviewSession(
        session_id=session_id,
        filename=file.filename,
        protocol_id=protocol_id,
        status='pending'
    )
    db.add(session)
    db.commit()
    
    try:
        # å®¡æ ¸é€»è¾‘...
        for issue in issues:
            # ä¿å­˜é—®é¢˜
            db_issue = ReviewIssue(
                session_id=session_id,
                issue_id=issue.issue_id,
                position=issue.position,
                rule_id=issue.rule_id,
                # ... å…¶ä»–å­—æ®µ
            )
            db.add(db_issue)
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        session.status = 'completed'
        session.completed_at = datetime.now()
        session.total_issues = len(issues)
        db.commit()
        
    except Exception as e:
        session.status = 'failed'
        db.commit()
        raise
    finally:
        db.close()
```

**æ—¥å¿—æŸ¥è¯¢æ¥å£**ï¼š
```python
@router.get("/logs/sessions")
async def list_sessions(
    limit: int = 20,
    offset: int = 0,
    status: Optional[str] = None
):
    """æŸ¥è¯¢å®¡æ ¸ä¼šè¯åˆ—è¡¨"""
    db = SessionLocal()
    query = db.query(ReviewSession)
    
    if status:
        query = query.filter(ReviewSession.status == status)
    
    sessions = query.order_by(ReviewSession.created_at.desc())\
                   .limit(limit)\
                   .offset(offset)\
                   .all()
    
    return {
        "total": query.count(),
        "sessions": [
            {
                "session_id": s.session_id,
                "filename": s.filename,
                "protocol_id": s.protocol_id,
                "total_issues": s.total_issues,
                "status": s.status,
                "created_at": s.created_at.isoformat()
            }
            for s in sessions
        ]
    }

@router.get("/logs/sessions/{session_id}")
async def get_session_detail(session_id: str):
    """æŸ¥è¯¢ä¼šè¯è¯¦æƒ…"""
    db = SessionLocal()
    session = db.query(ReviewSession)\
                .filter(ReviewSession.session_id == session_id)\
                .first()
    
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    
    issues = db.query(ReviewIssue)\
               .filter(ReviewIssue.session_id == session_id)\
               .all()
    
    return {
        "session": {...},
        "issues": [...]
    }
```

---

## âš¡ çŸ­æœŸä¼˜åŒ–ï¼ˆP1 - 1-2å‘¨å†…å®Œæˆï¼‰

### 4. æ‰¹é‡å¹¶å‘å®¡æ ¸

**é—®é¢˜**ï¼šå½“å‰æ˜¯ä¸²è¡Œå®¡æ ¸æ¯ä¸ªå—ï¼Œé€Ÿåº¦è¾ƒæ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# app/core/reviewer.py
async def review_chunks_batch(
    self,
    chunks: List[DocumentChunk],
    protocol_id: str,
    batch_size: int = 5
) -> List[List[Issue]]:
    """æ‰¹é‡å¹¶å‘å®¡æ ¸"""
    all_results = []
    
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]
        
        # å¹¶å‘æ‰§è¡Œ
        tasks = [
            self._review_chunk(chunk, protocol_id)
            for chunk in batch
        ]
        
        # ç­‰å¾…æ‰¹æ¬¡å®Œæˆ
        batch_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸
        for j, result in enumerate(batch_results):
            if isinstance(result, Exception):
                logger.error(f"å— {batch[j].chunk_id} å®¡æ ¸å¤±è´¥: {result}")
                all_results.append([])
            else:
                all_results.append(result)
        
        # é¿å… API é™æµ
        await asyncio.sleep(0.5)
    
    return all_results
```

**é¢„æœŸæ•ˆæœ**ï¼š
- é€Ÿåº¦æå‡ 2-3 å€
- æ›´å¥½åœ°åˆ©ç”¨ API å¹¶å‘èƒ½åŠ›

---

### 5. å®¡æ ¸æŠ¥å‘Šå¯¼å‡º

**åŠŸèƒ½**ï¼šå¯¼å‡º Word/PDF æ ¼å¼çš„å®¡æ ¸æŠ¥å‘Š

**å®ç°**ï¼š
```python
# app/api/review.py
from docx import Document
from docx.shared import Pt, RGBColor

@router.get("/review/{session_id}/export")
async def export_report(
    session_id: str,
    format: str = "docx"
):
    """å¯¼å‡ºå®¡æ ¸æŠ¥å‘Š"""
    # æŸ¥è¯¢å®¡æ ¸æ•°æ®
    db = SessionLocal()
    session = db.query(ReviewSession).filter(...).first()
    issues = db.query(ReviewIssue).filter(...).all()
    
    if format == "docx":
        # åˆ›å»º Word æ–‡æ¡£
        doc = Document()
        
        # æ ‡é¢˜
        title = doc.add_heading('æ–‡æ¡£å®¡æ ¸æŠ¥å‘Š', 0)
        
        # åŸºæœ¬ä¿¡æ¯
        doc.add_heading('ä¸€ã€åŸºæœ¬ä¿¡æ¯', 1)
        doc.add_paragraph(f'æ–‡æ¡£åç§°ï¼š{session.filename}')
        doc.add_paragraph(f'å®¡æ ¸æ ‡å‡†ï¼š{session.protocol_id}')
        doc.add_paragraph(f'å®¡æ ¸æ—¶é—´ï¼š{session.created_at}')
        
        # ç»Ÿè®¡æ‘˜è¦
        doc.add_heading('äºŒã€å®¡æ ¸æ‘˜è¦', 1)
        doc.add_paragraph(f'æ€»é—®é¢˜æ•°ï¼š{session.total_issues}')
        
        # é—®é¢˜è¯¦æƒ…
        doc.add_heading('ä¸‰ã€é—®é¢˜è¯¦æƒ…', 1)
        for i, issue in enumerate(issues, 1):
            doc.add_heading(f'{i}. {issue.category}', 2)
            doc.add_paragraph(f'ä½ç½®ï¼š{issue.position}')
            doc.add_paragraph(f'åŸæ–‡ï¼š{issue.original_text}')
            doc.add_paragraph(f'é—®é¢˜ï¼š{issue.issue_description}')
            doc.add_paragraph(f'å»ºè®®ï¼š{issue.suggestion}')
            doc.add_paragraph('')
        
        # ä¿å­˜
        output_path = f'data/reports/{session_id}.docx'
        doc.save(output_path)
        
        return FileResponse(
            path=output_path,
            filename=f'å®¡æ ¸æŠ¥å‘Š_{session.filename}.docx',
            media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        )
```

---

### 6. æ ‡å‡†ç®¡ç†åŠŸèƒ½å®Œå–„

**åŠŸèƒ½**ï¼šåœ¨çº¿ç®¡ç†æ ‡å‡†è§„åˆ™

**å‰ç«¯é¡µé¢**ï¼ˆ`standards.html`ï¼‰ï¼š
```html
<!DOCTYPE html>
<html>
<head>
    <title>æ ‡å‡†ç®¡ç†</title>
</head>
<body>
    <div class="container">
        <h1>æ ‡å‡†ç®¡ç†</h1>
        
        <!-- æ ‡å‡†åˆ—è¡¨ -->
        <div class="standards-list">
            <table>
                <thead>
                    <tr>
                        <th>åè®®ID</th>
                        <th>åç§°</th>
                        <th>ç‰ˆæœ¬</th>
                        <th>è§„åˆ™æ•°</th>
                        <th>æ“ä½œ</th>
                    </tr>
                </thead>
                <tbody id="standardsList"></tbody>
            </table>
        </div>
        
        <!-- ä¸Šä¼ æ–°æ ‡å‡† -->
        <div class="upload-section">
            <h2>ä¸Šä¼ æ–°æ ‡å‡†</h2>
            <input type="file" id="standardFile" accept=".docx">
            <button onclick="uploadStandard()">ä¸Šä¼ </button>
        </div>
    </div>
    
    <script>
        // åŠ è½½æ ‡å‡†åˆ—è¡¨
        async function loadStandards() {
            const response = await fetch('/api/standards/list');
            const data = await response.json();
            // æ¸²æŸ“åˆ—è¡¨
        }
        
        // ä¸Šä¼ æ ‡å‡†
        async function uploadStandard() {
            const file = document.getElementById('standardFile').files[0];
            const formData = new FormData();
            formData.append('file', file);
            
            const response = await fetch('/api/standards/upload', {
                method: 'POST',
                body: formData
            });
            
            if (response.ok) {
                alert('ä¸Šä¼ æˆåŠŸ');
                loadStandards();
            }
        }
    </script>
</body>
</html>
```

---

### 7. ç”¨æˆ·åé¦ˆæœºåˆ¶

**åŠŸèƒ½**ï¼šæ”¶é›†ç”¨æˆ·å¯¹å®¡æ ¸ç»“æœçš„åé¦ˆï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹

**å‰ç«¯**ï¼š
```javascript
// åœ¨æ¯ä¸ªé—®é¢˜å¡ç‰‡ä¸Šæ·»åŠ åé¦ˆæŒ‰é’®
function addIssueToList(issue, index) {
    issueDiv.innerHTML = `
        ...
        <div class="feedback-buttons">
            <button onclick="submitFeedback('${issue.issue_id}', true)">
                âœ… æ­£ç¡®
            </button>
            <button onclick="submitFeedback('${issue.issue_id}', false)">
                âŒ è¯¯æŠ¥
            </button>
        </div>
    `;
}

async function submitFeedback(issueId, isCorrect) {
    await fetch('/api/review/feedback', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({
            issue_id: issueId,
            is_correct: isCorrect
        })
    });
    alert('æ„Ÿè°¢åé¦ˆï¼');
}
```

**åç«¯**ï¼š
```python
@router.post("/feedback")
async def submit_feedback(
    issue_id: str = Form(...),
    is_correct: bool = Form(...),
    comment: Optional[str] = Form(None)
):
    """ç”¨æˆ·åé¦ˆ"""
    # æŸ¥è¯¢é—®é¢˜
    db = SessionLocal()
    issue = db.query(ReviewIssue).filter(...).first()
    
    # æ›´æ–°ç½®ä¿¡åº¦æ ¡å‡†å™¨
    reviewer.calibrator.update_history(issue.rule_id, is_correct)
    
    # ä¿å­˜åé¦ˆ
    feedback = Feedback(
        issue_id=issue_id,
        is_correct=is_correct,
        comment=comment
    )
    db.add(feedback)
    db.commit()
    
    return {"success": True}
```

---

## ğŸ¯ ä¸­æœŸå¢å¼ºï¼ˆP2 - 1ä¸ªæœˆå†…å®Œæˆï¼‰

### 8. å•å…ƒæµ‹è¯•

**æµ‹è¯•æ¡†æ¶**ï¼špytest

**æµ‹è¯•ç”¨ä¾‹ç¤ºä¾‹**ï¼š
```python
# tests/test_chunker.py
import pytest
from app.core.chunker import SmartChunker

def test_chunk_by_paragraphs():
    """æµ‹è¯•æ®µè½åˆ†å—"""
    chunker = SmartChunker()
    doc_structure = {
        "paragraphs": [
            {"text": "ç¬¬ä¸€æ®µå†…å®¹" * 20, "section": "ç¬¬ä¸€ç« "},
            {"text": "ç¬¬äºŒæ®µå†…å®¹" * 20, "section": "ç¬¬ä¸€ç« "},
        ]
    }
    
    chunks = chunker.chunk_by_paragraphs(doc_structure)
    
    assert len(chunks) > 0
    assert all(len(c.text) >= chunker.min_chunk_size for c in chunks)
    assert all(c.section == "ç¬¬ä¸€ç« " for c in chunks)

def test_filter_garbage_paragraphs():
    """æµ‹è¯•åƒåœ¾æ®µè½è¿‡æ»¤"""
    chunker = SmartChunker()
    doc_structure = {
        "paragraphs": [
            {"text": "", "section": ""},  # ç©ºæ®µè½
            {"text": "ã€‚ã€‚ã€‚", "section": ""},  # åªæœ‰æ ‡ç‚¹
            {"text": "æ­£å¸¸æ®µè½å†…å®¹", "section": "ç¬¬ä¸€ç« "},
        ]
    }
    
    chunks = chunker.chunk_by_paragraphs(doc_structure)
    
    assert len(chunks) == 1
    assert chunks[0].text == "æ­£å¸¸æ®µè½å†…å®¹"

# tests/test_optimizer.py
def test_should_skip_chunk():
    """æµ‹è¯•æ™ºèƒ½è·³è¿‡"""
    optimizer = SmartReviewOptimizer()
    
    # æµ‹è¯•ç©ºæ–‡æœ¬
    chunk = DocumentChunk(text="", ...)
    should_skip, reason = optimizer.should_skip_chunk(chunk, ...)
    assert should_skip == True
    assert reason == "æ–‡æœ¬å¤ªçŸ­"
    
    # æµ‹è¯•æ­£å¸¸æ–‡æœ¬
    chunk = DocumentChunk(text="è¿™æ˜¯ä¸€æ®µæ­£å¸¸çš„æ–‡æœ¬å†…å®¹" * 5, ...)
    should_skip, reason = optimizer.should_skip_chunk(chunk, ...)
    assert should_skip == False

# tests/test_calibrator.py
def test_calibrate_issue():
    """æµ‹è¯•ç½®ä¿¡åº¦æ ¡å‡†"""
    calibrator = ConfidenceCalibrator()
    
    issue = Issue(
        confidence=0.8,
        original_text="æµ‹è¯•æ–‡æœ¬",
        severity=Severity.HIGH,
        ...
    )
    
    calibrated = calibrator.calibrate_issue(
        issue,
        rule_type="format",
        chunk_text="åŒ…å«æµ‹è¯•æ–‡æœ¬çš„å®Œæ•´æ®µè½"
    )
    
    # format ç±»è§„åˆ™åº”è¯¥æé«˜ç½®ä¿¡åº¦
    assert calibrated.confidence > 0.8
```

**è¿è¡Œæµ‹è¯•**ï¼š
```bash
# å®‰è£… pytest
pip install pytest pytest-asyncio pytest-cov

# è¿è¡Œæµ‹è¯•
pytest tests/ -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=app --cov-report=html
```

---

### 9. å¤šæ–‡æ¡£æ‰¹é‡å®¡æ ¸

**åŠŸèƒ½**ï¼šä¸€æ¬¡ä¸Šä¼ å¤šä¸ªæ–‡æ¡£ï¼Œæ‰¹é‡å®¡æ ¸

**å®ç°**ï¼š
```python
@router.post("/review/batch")
async def batch_review(
    files: List[UploadFile] = File(...),
    protocol_id: str = Form(...)
):
    """æ‰¹é‡å®¡æ ¸å¤šä¸ªæ–‡æ¡£"""
    results = []
    
    for file in files:
        try:
            # ä¿å­˜æ–‡ä»¶
            file_path = save_upload_file(file)
            
            # å®¡æ ¸
            result = await review_single_document(file_path, protocol_id)
            
            results.append({
                "filename": file.filename,
                "success": True,
                "total_issues": result.total_issues,
                "session_id": result.session_id
            })
            
        except Exception as e:
            results.append({
                "filename": file.filename,
                "success": False,
                "error": str(e)
            })
    
    return {
        "total": len(files),
        "success": sum(1 for r in results if r['success']),
        "failed": sum(1 for r in results if not r['success']),
        "results": results
    }
```

---

### 10. å‰ç«¯æ€§èƒ½ä¼˜åŒ–

**é—®é¢˜**ï¼šå¤§é‡é—®é¢˜æ—¶ DOM æ¸²æŸ“å¡é¡¿

**è§£å†³æ–¹æ¡ˆ - è™šæ‹Ÿæ»šåŠ¨**ï¼š
```javascript
// ä½¿ç”¨ Intersection Observer å®ç°è™šæ‹Ÿæ»šåŠ¨
class VirtualList {
    constructor(container, items, renderItem) {
        this.container = container;
        this.items = items;
        this.renderItem = renderItem;
        this.visibleItems = new Set();
        this.init();
    }
    
    init() {
        // åˆ›å»ºå ä½å…ƒç´ 
        this.items.forEach((item, index) => {
            const placeholder = document.createElement('div');
            placeholder.dataset.index = index;
            placeholder.style.minHeight = '100px';
            this.container.appendChild(placeholder);
            
            // ç›‘å¬å¯è§æ€§
            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        this.renderItem(placeholder, item);
                        this.visibleItems.add(index);
                    } else {
                        placeholder.innerHTML = '';
                        this.visibleItems.delete(index);
                    }
                });
            });
            
            observer.observe(placeholder);
        });
    }
}

// ä½¿ç”¨
const virtualList = new VirtualList(
    document.getElementById('issueList'),
    issues,
    (element, issue) => {
        element.innerHTML = renderIssueHTML(issue);
    }
);
```

---

## ğŸ“š é•¿æœŸè§„åˆ’ï¼ˆP3 - 2-3ä¸ªæœˆï¼‰

### 11. Docker éƒ¨ç½²æ–¹æ¡ˆ

**Dockerfile**ï¼š
```dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY backend/ ./backend/
COPY standards/ ./standards/
COPY frontend/ ./frontend/

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨æœåŠ¡
CMD ["python", "backend/main.py"]
```

**docker-compose.yml**ï¼š
```yaml
version: '3.8'

services:
  docreviewer:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    environment:
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
    restart: unless-stopped
```

---

### 12. å®¡æ ¸ç»Ÿè®¡åˆ†æ

**åŠŸèƒ½**ï¼š
- å®¡æ ¸è¶‹åŠ¿åˆ†æ
- å¸¸è§é—®é¢˜ç»Ÿè®¡
- è§„åˆ™å‘½ä¸­ç‡åˆ†æ

**å®ç°**ï¼š
```python
@router.get("/statistics/overview")
async def get_statistics():
    """è·å–ç»Ÿè®¡æ¦‚è§ˆ"""
    db = SessionLocal()
    
    # æ€»å®¡æ ¸æ¬¡æ•°
    total_sessions = db.query(ReviewSession).count()
    
    # æ€»é—®é¢˜æ•°
    total_issues = db.query(ReviewIssue).count()
    
    # æŒ‰ä¸¥é‡åº¦ç»Ÿè®¡
    severity_stats = db.query(
        ReviewIssue.severity,
        func.count(ReviewIssue.id)
    ).group_by(ReviewIssue.severity).all()
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    category_stats = db.query(
        ReviewIssue.category,
        func.count(ReviewIssue.id)
    ).group_by(ReviewIssue.category)\
     .order_by(func.count(ReviewIssue.id).desc())\
     .limit(10).all()
    
    # è§„åˆ™å‘½ä¸­ç‡
    rule_stats = db.query(
        ReviewIssue.rule_id,
        func.count(ReviewIssue.id)
    ).group_by(ReviewIssue.rule_id)\
     .order_by(func.count(ReviewIssue.id).desc())\
     .limit(10).all()
    
    return {
        "total_sessions": total_sessions,
        "total_issues": total_issues,
        "severity_distribution": dict(severity_stats),
        "top_categories": dict(category_stats),
        "top_rules": dict(rule_stats)
    }
```

---

### 13. è§„åˆ™è‡ªåŠ¨å­¦ä¹ ä¼˜åŒ–

**åŠŸèƒ½**ï¼šæ ¹æ®ç”¨æˆ·åé¦ˆè‡ªåŠ¨è°ƒæ•´è§„åˆ™æƒé‡

**å®ç°æ€è·¯**ï¼š
1. æ”¶é›†ç”¨æˆ·åé¦ˆæ•°æ®
2. ç»Ÿè®¡æ¯æ¡è§„åˆ™çš„å‡†ç¡®ç‡
3. è‡ªåŠ¨è°ƒæ•´è§„åˆ™çš„ç›¸ä¼¼åº¦é˜ˆå€¼
4. å®šæœŸé‡æ–°è®­ç»ƒè§„åˆ™å‘é‡

---

## ğŸ“Š ä¼˜å…ˆçº§æ€»ç»“

| ä¼˜å…ˆçº§ | ä»»åŠ¡ | é¢„è®¡å·¥ä½œé‡ | é‡è¦æ€§ |
|--------|------|------------|--------|
| P0 | åˆ é™¤ç¡¬ç¼–ç  API Key | 0.5å¤© | â­â­â­â­â­ |
| P0 | å®Œå–„é”™è¯¯å¤„ç† | 1å¤© | â­â­â­â­â­ |
| P0 | å®ç°æ—¥å¿—æŒä¹…åŒ– | 2å¤© | â­â­â­â­â­ |
| P1 | æ‰¹é‡å¹¶å‘å®¡æ ¸ | 1å¤© | â­â­â­â­ |
| P1 | å®¡æ ¸æŠ¥å‘Šå¯¼å‡º | 1å¤© | â­â­â­â­ |
| P1 | æ ‡å‡†ç®¡ç†åŠŸèƒ½ | 2å¤© | â­â­â­â­ |
| P1 | ç”¨æˆ·åé¦ˆæœºåˆ¶ | 1å¤© | â­â­â­ |
| P2 | å•å…ƒæµ‹è¯• | 3å¤© | â­â­â­â­ |
| P2 | å¤šæ–‡æ¡£æ‰¹é‡å®¡æ ¸ | 1å¤© | â­â­â­ |
| P2 | å‰ç«¯æ€§èƒ½ä¼˜åŒ– | 2å¤© | â­â­â­ |
| P3 | Docker éƒ¨ç½² | 1å¤© | â­â­â­ |
| P3 | ç»Ÿè®¡åˆ†æ | 2å¤© | â­â­ |
| P3 | è§„åˆ™å­¦ä¹ ä¼˜åŒ– | 5å¤© | â­â­ |

**æ€»è®¡**ï¼šçº¦ 22.5 ä¸ªå·¥ä½œæ—¥

---

## ğŸ¯ å®æ–½å»ºè®®

### ç¬¬ä¸€å‘¨ï¼ˆP0 ä»»åŠ¡ï¼‰
- Day 1: åˆ é™¤ç¡¬ç¼–ç  API Key + å®Œå–„é”™è¯¯å¤„ç†
- Day 2-3: å®ç°æ—¥å¿—æŒä¹…åŒ–ï¼ˆæ•°æ®åº“è®¾è®¡ + APIï¼‰
- Day 4: æµ‹è¯•å’Œæ–‡æ¡£æ›´æ–°

### ç¬¬äºŒå‘¨ï¼ˆP1 ä»»åŠ¡ - ä¸ŠåŠéƒ¨åˆ†ï¼‰
- Day 1: æ‰¹é‡å¹¶å‘å®¡æ ¸
- Day 2: å®¡æ ¸æŠ¥å‘Šå¯¼å‡º
- Day 3-4: æ ‡å‡†ç®¡ç†åŠŸèƒ½ï¼ˆå‰åç«¯ï¼‰
- Day 5: ç”¨æˆ·åé¦ˆæœºåˆ¶

### ç¬¬ä¸‰å‘¨ï¼ˆP2 ä»»åŠ¡ï¼‰
- Day 1-3: å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–æ ¸å¿ƒæ¨¡å—ï¼‰
- Day 4: å¤šæ–‡æ¡£æ‰¹é‡å®¡æ ¸
- Day 5: å‰ç«¯æ€§èƒ½ä¼˜åŒ–

### ç¬¬å››å‘¨ï¼ˆP3 ä»»åŠ¡ + æ€»ç»“ï¼‰
- Day 1: Docker éƒ¨ç½²æ–¹æ¡ˆ
- Day 2: ç»Ÿè®¡åˆ†æåŠŸèƒ½
- Day 3-4: æ–‡æ¡£å®Œå–„
- Day 5: é¡¹ç›®æ€»ç»“å’Œæ¼”ç¤º

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æœ€åæ›´æ–°**ï¼š2026å¹´2æœˆ15æ—¥

